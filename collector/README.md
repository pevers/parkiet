# Data

We collected a list of popular Dutch podcasts and transcribed the audio.
Quality control is done via the transcription model and the audio is then split into segments up to 30 seconds after which prompts are generated.

Strategy to collect sensible data:

- Skip the trailer episodes
- Skip the start of the episode
- Skip non-Dutch baked in server side ads

```
uv run python src/download_podcasts.py
```

## Plan

- Use AssemblyAI to transcribe the audio with speaker diarization and preferably support for disfluencies
- Chunk the segments and throw away bad predictions. Chunks are stored in `data/chunks`
- Use English SER model to label the chunks with emotions. Fine-tune the model on a small set of Dutch data if quality is not good enough
- Create prompts and optionally add fuzzing through a GPT. Prompts are stored in `data/prompts`

### Speaker Diarization

Whisper doesn't support speaker diarization out of the box. So we use AssemblyAI (which is extremely accurate). 

Costs are $0.37 / h. So at 300 hours that's only $111.

### SER

We might need a high quality Dutch dataset to fine-tune the model a bit further.
This shouldn't be too hard to create. I know some voice actors that can help out.

### Prompt Generation

TODO: Add *fluent* prompts on transcripts with disfluencies disabled.

TODO: Add *fuzzing* prompts by using a GPT to generate script variations.

Prompts are generated by sampling pairs from the chunks. 

## Viewer

In order to quickly inspect data and adjust annotations, we need a viewer.
This simple CLI script can be used as follows:

```
uv run python src/viewer.py <path_to_chunks.json>
```
