# Data

We collected a list of popular Dutch podcasts and transcribed the audio.
Quality control is done via the transcription model and the audio is then split into segments up to 30 seconds.

Strategy to collect sensible data:

- Skip the trailer episodes
- Skip the start of the episode (through AssemblyAI?)
- We need to use AssemblyAI to skip intros and other parts with baked in advertisement

```
uv run python src/download_podcasts.py
```

## Classifier

The classifier is a pre-processing step to generate a lot of synthetic data for the Parakeet model.

### Plan

- Use Whisper to transcribe the audio
- Chunk the segments using Whisper and throw away bad predictions
- Finetune a SER model for Dutch audio. It seems to work quite well already for English. We need to accurately do speaker identification and split the audio.
- Use this model to enhance text with SER tokens

### Speaker Diarization

Whisper doesn't support speaker diarization out of the box. So we use AssemblyAI (which is extremely accurate). 

Costs are $0.37 / h. So at 300 hours that's only $111.

### SER

We might need a high quality Dutch dataset to fine-tune the model a bit further.
This shouldn't be too hard to create. I know some voice actors that can help out.

The strategy is the following:

- Use the AssemblyAI API to transcribe the audio
- Then split the audio in chunks per speaker
- Run the English SER model on the chunks to label it
- Generate the synthetic data and store it in chunks.json

### Prompt Generation

TODO: Add *fluent* prompts on transcripts with disfluencies disabled.
TODO: Add *fuzzing* prompts by using a GPT to generate script variations.

Prompts are generated by sampling pairs from the chunks. 

## Viewer

In order to quickly inspect data and adjust annotations, we need a viewer.
This simple CLI script can be used as follows:

```
uv run python src/viewer.py <path_to_chunks.json>
```
